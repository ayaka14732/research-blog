<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-GB" xml:lang="en-GB" dir="ltr">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Ayaka" />
  <title>The Wakong Algorithm and Its Python Implementation</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="/pandoc.css" />
  <link rel="stylesheet" href="/font.css" />
  <!-- Others -->
  <meta property="og:image" content="https://avatars2.githubusercontent.com/u/68557794?s=400&u=343da7bebff676129e87341def71121ebffc4c9c&v=4"/>
  <script>
    window.addEventListener('DOMContentLoaded', function() {
      var xs = document.getElementsByTagName('code');
      for (var i = 0, len = xs.length; i < len; i++)
        xs[i].lang = 'en-x-code';
      xs = document.getElementsByClassName('footnote-back');
      for (var i = 0, len = xs.length; i < len; i++)
        xs[i].lang = 'en-x-code';
      document.querySelectorAll('div.sourceCode > pre').forEach(function(x) {
        x.classList.add('numberSource');
      });
    });
  </script>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">The Wakong Algorithm and Its Python
Implementation</h1>
<p class="author">Ayaka</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction" id="toc-introduction">Introduction</a></li>
<li><a href="#problem-formulation" id="toc-problem-formulation">Problem
Formulation</a>
<ul>
<li><a href="#input-and-output-of-the-algorithm"
id="toc-input-and-output-of-the-algorithm">Input and output of the
algorithm</a></li>
<li><a href="#requirements-of-the-algorithm"
id="toc-requirements-of-the-algorithm">Requirements of the
algorithm</a></li>
</ul></li>
<li><a href="#the-algorithm" id="toc-the-algorithm">The
Algorithm</a></li>
<li><a href="#time-complexity" id="toc-time-complexity">Time
Complexity</a></li>
<li><a href="#difficulties-in-the-design-of-the-algorithm"
id="toc-difficulties-in-the-design-of-the-algorithm">Difficulties in the
Design of the Algorithm</a>
<ul>
<li><a
href="#determining-the-number-of-words-to-be-masked-in-a-sentence"
id="toc-determining-the-number-of-words-to-be-masked-in-a-sentence">Determining
the number of words to be masked in a sentence</a></li>
<li><a href="#randomly-selecting-the-length-of-the-mask"
id="toc-randomly-selecting-the-length-of-the-mask">Randomly selecting
the length of the mask</a></li>
<li><a href="#generate-a-list-of-the-lengths-of-the-masks"
id="toc-generate-a-list-of-the-lengths-of-the-masks">Generate a list of
the lengths of the masks</a></li>
<li><a href="#distributing-the-masks-evenly-across-the-sentences"
id="toc-distributing-the-masks-evenly-across-the-sentences">Distributing
the masks evenly across the sentences</a></li>
<li><a href="#adjusting-the-parameters"
id="toc-adjusting-the-parameters">Adjusting the parameters</a></li>
</ul></li>
<li><a href="#python-implementation"
id="toc-python-implementation">Python Implementation</a></li>
</ul>
</nav>
<h1 id="introduction">Introduction</h1>
<p>Sentence masking is a common procedure in the pre-training of deep
learning models. For instance, in the pre-training of the BART model,
there is a training objective named text infilling. The aim of text
infilling is to let the model acquire the ability to fill in the blanks,
which requires the development of a masking algorithm to generate masked
sentences for the training. However, existing papers (TODO: who?)
provide only vague descriptions of the masking methods in their
experiments, which are merely theoretical and cannot really be
implemented as algorithms; while most of the implementations only design
roughly usable algorithms without in-depth analysis. In response, we
propose an appropriate and robust masking algorithm (the wakong
algorithm), and publishes a Python library that can be used directly in
production.</p>
<h1 id="problem-formulation">Problem Formulation</h1>
<h2 id="input-and-output-of-the-algorithm">Input and output of the
algorithm</h2>
<p>A sentence masking algorithm is an algorithm for masking a sentence
of a fixed length. The input of the algorithm is the length of the
sentence, denoted by <code>seq_len</code>, and the output is a list of
tuples. Each tuple represents a mask in the original sentence. The first
element represents the starting position of the mask and the second
element represents the length.</p>
<p>For example, when the length of the input sentence 40, the output of
the algorithm might be:</p>
<pre><code>[(5, 4), (23, 2)]</code></pre>
<p>This output indicates that two positions of the sentence are masked.
The first one starts at position 5 and has a length of 4, while the
second starts at position 23 and has a length of 2. It can also be
represented graphically as follows:</p>
<pre><code>.....(xxxx)..............(xx)...............</code></pre>
<h2 id="requirements-of-the-algorithm">Requirements of the
algorithm</h2>
<p>Based on the BART paper, we suggest that a reasonable sentence
masking algorithm should satisfy the following four requirements:</p>
<ol type="1">
<li>The masking algorithm is a stochastic algorithm, i.e.Â the algorithm
may output different results even if the inputs are the same. This is to
allow for a greater variety of masking schemes, so that models can
better acquire knowledge of cloze tests;</li>
<li>The number of words masked by the masking algorithm should be 15% on
average. This number was chosen to be moderate enough not to make the
pre-training target too simple, while retaining a certain amount of
semantic information that would allow the cloze test to be
completed;</li>
<li>The length of each blank in the masking algorithm is variable,
ranging from 0 to 10, with blanks of length 3 occurring most frequently.
The frequency increases from 0 to 3 and decreases from 3 to 10. Blanks
of length 0 may occur. This is to allow the model to learn that no words
may be required in the cloze test, increasing the difficulty of the
training and thus allowing the model to learn more semantic
knowledge.</li>
<li>Any two masks in the masking algorithm must not overlap or be
directly adjacent to each other. They must have a distance of at least
1. This is to ensure that the output of the algorithm is
well-formed.</li>
</ol>
<h1 id="the-algorithm">The Algorithm</h1>
<p>1. Constants</p>
<p><span class="math inline">\mathsf{proposedMaskRate} =
0.188</span></p>
<p><span class="math inline">\mathsf{poissonRate} = 4.2</span></p>
<p><span class="math inline">\mathsf{maxSpanLen} = 10</span></p>
<p>2. <code>probsList</code></p>
<p><span class="math inline">\mathsf{probsList} = \left[
\mathrm{normalise} \left( \mathsf{probs} \left[ {:}\,i \right] \right)
\mathrm{for} \; i \; \mathrm{in} \left[2, \; .. , \; \mathsf{maxSpanLen}
+ 1 \right] \right]</span></p>
<p><span class="math inline">\mathsf{probs} = \left[ \Pr(X=i) \;
\mathrm{for} \; i \; \mathrm{in} \left[ 0, \; .., \; \mathsf{maxSpanLen}
+ 1 \right] \right]</span></p>
<p><span class="math inline">X \sim
\mathrm{Pois}(\mathsf{poissonRate})</span></p>
<p>3. <code>determineShouldMaskLen</code></p>
<p><span class="math inline">\mathsf{determineShouldMaskLen} \left(
\mathsf{seqLen} \right) = \begin{cases}  \lceil x \rceil, &amp;
\text{if} \; \omega &lt; p \\  \lfloor x \rfloor, &amp; \text{otherwise}
\\ \end{cases}</span></p>
<p><span class="math inline">\omega \sim \mathrm{U} \left( 0, 1
\right)</span></p>
<p><span class="math inline">x = \mathsf{seqLen} *
\mathsf{proposedMaskRate}</span></p>
<p><span class="math inline">p = x - \lfloor x \rfloor</span></p>
<p>4. <code>generateSpans</code></p>
<p><span class="math inline">\mathsf{generateSpans} \left( m \right) =
\mathrm{shuffle} \left( \mathrm{anamorphism} \left( f \right) \left( m
\right) \right)</span></p>
<p><span class="math inline">f \left( \mathsf{remainedLen} \right) =
\begin{cases}  \mathrm{Nothing}, &amp; \text{if} \; \mathsf{remainedLen}
\leq 0 \\  \left( \mathsf{span}, \; \mathrm{Just} \left(
\mathsf{remainedLen} - \mathsf{span} - 1 \right) \right), &amp;
\text{otherwise} \end{cases}</span></p>
<p><span class="math inline">\mathsf{span} \sim \mathrm{Categorical}
\left( [0, \; .., \; n + 1], \; \mathsf{probsList} \left[ n - 1 \right]
\right)</span></p>
<p><span class="math inline">n = \min \left( \mathsf{maxSpanLen}, \;
\mathsf{remainedLen} \right)</span></p>
<p>5. <code>distributeInsertPoses</code></p>
<p><span class="math inline">\mathsf{distributeInsertPoses} \left(
\mathsf{xs} \right) = f \left( \mathsf{xs}, \; 0 \right)</span></p>
<p><span class="math inline">f \left( n, \; \mathsf{xs} \right) =
\begin{cases}  \mathsf{\left[ \, \right]}, &amp; \text{if} \;
\mathrm{empty} \left( \mathsf{xs} \right) \\  \left[ \left( p + n, \; s
\right) \right] + f \left(n + s + 1, \; \mathsf{ys} \right), &amp;
\text{otherwise} \\ \end{cases}</span></p>
<p><span class="math inline">\left[ \left( p, s \right) \right] +
\mathsf{ys} \leftarrow \mathsf{xs}</span></p>
<p>6. <code>randomAddOne</code></p>
<p><span class="math inline">\mathsf{randomAddOne} \left( \mathsf{xs}
\right) = \begin{cases}  \mathsf{xs}, &amp; \text{if} \; \omega &lt; 0.5
\\  \left[ (p + 1, s) \; \mathrm{for} \; (p, s) \; \mathrm{in} \;
\mathsf{xs} \right], &amp; \text{otherwise} \\ \end{cases}</span></p>
<p><span class="math inline">\omega \sim \mathrm{U} \left( 0, 1
\right)</span></p>
<p>7. <code>wakong</code></p>
<p><span class="math inline">\mathsf{wakong} \left( \mathsf{seqLen}
\right) = \mathsf{randomAddOne} \left( \mathsf{distributeInsertPoses}
\left( \mathrm{zip} \left( \mathsf{absInsertPoses}, \; \mathsf{spans}
\right) \right) \right)</span></p>
<p><span class="math inline">\mathsf{absInsertPoses} = \mathrm{sort}
\left( X \right)</span></p>
<p><span class="math inline">X = X_{1, \; .., \; \mathsf{nSpans}} \sim
\mathrm{DiscreteUniform} \left[ 0, \; \mathsf{nPossibleInsertPoses} - 1
\right]</span></p>
<p><span class="math inline">\left( \forall \; i, j \in \left\{ 1, \;
.., \; \mathsf{nSpans} \right\}, X_i \ne X_j \right)</span></p>
<p><span class="math inline">\mathsf{nPossibleInsertPoses} =
\mathsf{seqLen} - \mathrm{sum} \left( \mathsf{spans} \right) -
\mathsf{nSpans} + 1</span></p>
<p><span class="math inline">\mathsf{nSpans} = \mathrm{len} \left(
\mathsf{spans} \right)</span></p>
<p><span class="math inline">\mathsf{spans} = \mathsf{generateSpans}
\left( \mathsf{shouldMaskLen} \right)</span></p>
<p><span class="math inline">\mathsf{shouldMaskLen} =
\mathsf{determineShouldMaskLen} \left( \mathsf{seqLen}
\right)</span></p>
<h1 id="time-complexity">Time Complexity</h1>
<p>The step with the highest time complexity in the algorithm is sorting
the randomly generated <span class="math inline">kn</span> blanks, so
the overall time complexity is <span class="math inline">O \left( n \log
n \right)</span>.</p>
<h1 id="difficulties-in-the-design-of-the-algorithm">Difficulties in the
Design of the Algorithm</h1>
<h2
id="determining-the-number-of-words-to-be-masked-in-a-sentence">Determining
the number of words to be masked in a sentence</h2>
<p>The algorithm requires that an average of 15% of the words in a
sentence should be masked, but this calculation sometimes results in
fractions. If this occur, we set the number of fractions to be rounded
down or up randomly according to the fractional places. For example, if
the number of words to be masked is calculated to be 3.3, a random
number is randomly generated once with a uniform distribution between 0
and 1, rounded up to 4 if the number is less than 0.3, otherwise rounded
down to 3.</p>
<h2 id="randomly-selecting-the-length-of-the-mask">Randomly selecting
the length of the mask</h2>
<p>Following the BART paper, we sample from a Poisson distribution to
randomly generate the length of the mask. Instead of setting the
parameter of the Poisson distribution to 4 as in the BART paper, we set
it to 3.5 so that masks of length 3 would occur most frequently
(however, as will be mentioned in a subsequent step, we revised this
parameter to 4.2). For values greater than 10, we set the probability to
0 and normalise the probability of values between 0 and 10 to sum to 1.
This produces a distribution with a cumulative distribution function of
[0.0151 0.0783 0.2111 0.3970 0.5922 0.7562 0.8710 0.9399 0.9760 0.9929
1.0000].</p>
<h2 id="generate-a-list-of-the-lengths-of-the-masks">Generate a list of
the lengths of the masks</h2>
<p>The list of mask lengths is generated by repeatedly sampling from the
above distribution. The sampling stops when the sum of the lengths of
the masks reaches the number of words to be masked.</p>
<p>If the sum of the lengths of the masks does not reach the target
number of words, but the sum of the lengths of the sampled results plus
the masks is greater than the target number of words (e.g.Â if the target
number of words is 10 and the current sum of lengths is 9, but the
sampled result is 5 and 9 plus 5 is greater than 10), the algorithm will
discard the result of that sample and resample it until the sum of the
lengths of the sampled results plus the masks is within the range of the
target number of words. In practice, in order to ensure the efficiency
of the algorithm, it should not re-sample when the sampling fails, but
should first calculate the range of expected sampling results based on
the sum of the lengths of the target words and the mask, then calculate
a new distribution based on the above distribution excluding the values
outside the expected range of sampling results, normalise the
probability to sum to 1 and sample from the new distribution.</p>
<p>The algorithm requires that any two masks cannot be directly adjacent
to each other, and a mask of length k actually occupies a position to
its right, i.e.Â the actual length is k+1. Therefore, when calculating
the sum of the lengths of the masks, the length of each mask needs to be
added by an extra 1, i.e.Â the sum of the lengths of the masks plus the
number of masks. Although this is a good way to avoid the problem of two
masks being directly adjacent to each other, it will result in a smaller
average number of words masked than the expected 15% (for this reason,
the average number of words masked will be adjusted to 18.8% in a
subsequent step to make the final result closer to 15%).</p>
<p>An asymmetry arises because samples of length 0 may occur at the
start of sampling, while samples of length 0 are unlikely to occur at
the end of sampling conditional on the target length being reached. For
this reason, the list of mask lengths should be randomly scrambled at
the end of sampling so that the lengths of the masks are randomly
distributed.</p>
<h2 id="distributing-the-masks-evenly-across-the-sentences">Distributing
the masks evenly across the sentences</h2>
<p>Let the length of the sentence be m, the sum of the lengths of the
masks be K, and the number of masks be n.Â There are m-K-n+1 possible
starting positions, and n of these starting positions are chosen at
random as the starting positions of the masks. The reason for
subtracting n is that, as mentioned above, a mask of length k actually
occupies a position to its right, so n masks will occupy an additional n
positions.</p>
<p>However, this would result in the last word of the sentence never
being masked. For this reason, after the above step, a random number
between 0 and 1 is randomly generated, and if this number is less than
0.5, all masks are shifted one place to the right, i.e.Â the empty space
is assumed to be on the left, thus ensuring the symmetry of the
algorithm.</p>
<h2 id="adjusting-the-parameters">Adjusting the parameters</h2>
<p>After implementing the algorithm, we found that the average number of
words masked was less than 15%. This is due to the fact that, as
mentioned above, the sum of the lengths of the masks is calculated by
adding an extra 1 to the length of each blank, resulting in the actual
number of words masked being less than the target number of words. For
this reason, it was found that by adjusting the average number of words
masked in the algorithm parameters to 18.8%, the final result was close
to 15.17%, which is close to the expected value of 15%.</p>
<p>In addition, the algorithm generated shorter length masks more
frequently than expected because the expected sampling results could
only occur at smaller values as the sampling neared its end. This is
allowed by the algorithm as it is only necessary to ensure that a mask
of length 3 occurs most frequently. However, in order to make the
algorithm generate masks of longer lengths more frequently in order to
make training more difficult, we modified the parameter of the Poisson
distribution from 3.5 to 4.2.</p>
<h1 id="python-implementation">Python Implementation</h1>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax.numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpyro.distributions <span class="im">as</span> dist</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> Random</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>proposed_mask_rate <span class="op">=</span> <span class="fl">0.188</span>  <span class="co"># resulting mask rate would be approximately 0.15</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>poisson_rate <span class="op">=</span> <span class="fl">4.2</span>  <span class="co"># span length = 3 would be the most frequent in the resulting distribution</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>max_span_len <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normalise_probs(a: np.ndarray) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a <span class="op">/</span> a.<span class="bu">sum</span>()</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_probs_list() <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">list</span>[<span class="bu">float</span>]]:</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    probs_list <span class="op">=</span> []</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    poisson <span class="op">=</span> dist.Poisson(rate<span class="op">=</span>poisson_rate)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> np.exp(poisson.log_prob(np.arange(max_span_len <span class="op">+</span> <span class="dv">1</span>)))</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    probs_ <span class="op">=</span> normalise_probs(probs)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    probs_list.append(probs_.cumsum().tolist())</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_span_len <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        probs_ <span class="op">=</span> normalise_probs(probs[:<span class="op">-</span>i<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>        probs_list.append(probs_.cumsum().tolist())</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> probs_list[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>probs_list <span class="op">=</span> generate_probs_list()</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>MaskScheme <span class="op">=</span> <span class="bu">list</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>]]</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> determine_should_mask_len(rng: Random, seq_len: <span class="bu">int</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> seq_len <span class="op">*</span> proposed_mask_rate</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    integer_part <span class="op">=</span> <span class="bu">int</span>(x)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    fractional_part <span class="op">=</span> x <span class="op">-</span> <span class="bu">float</span>(integer_part)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    should_add <span class="op">=</span> rng.random() <span class="op">&lt;</span> fractional_part</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    should_mask_len <span class="op">=</span> integer_part <span class="op">+</span> should_add</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> should_mask_len</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_spans(rng: Random, should_mask_len: <span class="bu">int</span>) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">int</span>]:</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    spans <span class="op">=</span> []</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> should_mask_len <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        current_max_span_len <span class="op">=</span> <span class="bu">min</span>(max_span_len, should_mask_len)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> probs_list[current_max_span_len <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>        span_len <span class="op">=</span> rng.choices(<span class="bu">range</span>(current_max_span_len <span class="op">+</span> <span class="dv">1</span>), cum_weights<span class="op">=</span>probs)[<span class="dv">0</span>]</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>        spans.append(span_len)</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>        should_mask_len <span class="op">-=</span> span_len <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    rng.shuffle(spans)</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> spans</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> distribute_insert_poses(abs_insert_poses: <span class="bu">list</span>[<span class="bu">int</span>], spans: <span class="bu">list</span>[<span class="bu">int</span>]) <span class="op">-&gt;</span> MaskScheme:</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>    offset <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>    mask_scheme <span class="op">=</span> []</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> abs_insert_pos, span <span class="kw">in</span> <span class="bu">zip</span>(abs_insert_poses, spans):</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>        insert_pos <span class="op">=</span> abs_insert_pos <span class="op">+</span> offset</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>        mask_scheme.append((insert_pos, span))</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>        offset <span class="op">+=</span> span <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mask_scheme</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> random_add_one(rng: Random, mask_scheme: MaskScheme) <span class="op">-&gt;</span> MaskScheme:</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>    should_add_one <span class="op">=</span> rng.random() <span class="op">&lt;</span> <span class="fl">0.5</span></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> should_add_one:</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>        mask_scheme <span class="op">=</span> [(insert_pos <span class="op">+</span> <span class="dv">1</span>, span) <span class="cf">for</span> insert_pos, span <span class="kw">in</span> mask_scheme]</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mask_scheme</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> wakong(rng: Random, seq_len: <span class="bu">int</span>) <span class="op">-&gt;</span> MaskScheme:</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>    should_mask_len <span class="op">=</span> determine_should_mask_len(rng, seq_len)</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a>    spans <span class="op">=</span> generate_spans(rng, should_mask_len)</span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>    n_spans <span class="op">=</span> <span class="bu">len</span>(spans)</span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>    n_possible_insert_poses <span class="op">=</span> seq_len <span class="op">-</span> <span class="bu">sum</span>(spans) <span class="op">-</span> n_spans <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>    abs_insert_poses <span class="op">=</span> <span class="bu">sorted</span>(rng.sample(<span class="bu">range</span>(n_possible_insert_poses), n_spans))</span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>    mask_scheme <span class="op">=</span> distribute_insert_poses(abs_insert_poses, spans)</span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>    mask_scheme <span class="op">=</span> random_add_one(rng, mask_scheme)</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mask_scheme</span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test():</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a>    seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a>    rng <span class="op">=</span> Random(seed)</span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a>    mask_scheme <span class="op">=</span> wakong(rng, <span class="dv">100</span>)</span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(mask_scheme)</span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:</span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a>    test()</span></code></pre></div>
</body>
</html>
